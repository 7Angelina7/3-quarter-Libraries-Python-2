{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e33e79b",
   "metadata": {},
   "source": [
    "### Задание 1. Расскажите, как работает регуляризация в решающих деревьях, какие параметры мы штрафуем в данных алгоритмах?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cadad52",
   "metadata": {},
   "source": [
    "Регуляризация это способ борьбы с переобучением.\n",
    "Регуляризация является штрафом за слишком большие веса.\n",
    "Штрафуя модель, мы ограничиваем то количество решений, которое в случае с мультиколлинеарностью слишком велико или бесконечно, \n",
    "некоторым набором решений. Да, в результате мы получаем несколько смещённую оценку, но она смещена не сильно. \n",
    "Таким образом от глобальной проблемы (задачу решить в принципе нельзя) мы переходим к конкретному результату, \n",
    "когда задача решена не самым оптимальным способом, но, тем не менее, устойчивое решение мы нашли.\n",
    "\n",
    "1) L1 - негладкий(модуль не имеет производной в 0).\n",
    "Т.е. оптимизация модели с таким регуляризатором будет затруднительна - интересное св-во: если использовать L1, то часть весов в итоговом векторе весов будут нулевыми.\n",
    "Т.e. L1 производит отбор признаков-использует в модели не все признаки, а только самые важные из них.\n",
    "\n",
    "2) L2 -гладкий и выпуклый(его добавление к функционалу не будет усложнять процесс оптимизации).\n",
    "\n",
    "Деревья решений легко переобучаются и процесс ветвления надо в какой-то момент останавливать.\n",
    "Для этого есть разные критерии, обычно используются все сразу:\n",
    "ограничение по максимальной глубине дерева;\n",
    "ограничение на минимальное количество объектов в листе;\n",
    "ограничение на максимальное количество листьев в дереве;\n",
    "требование, чтобы функционал качества Branch при делении текущей подвыборки на две улучшался не менее чем на s процентов.\n",
    "\n",
    "L2 регуляризация штрафует большие значения весов, заставляя их приближаться к нулю, но в отличие от L1 регуляризации не зануляет их полностью. Вместо этого L2 регуляризация штрафует большие значения весов более гладко и непрерывно, что позволяет более уверенно управлять компромиссом между точностью и сложностью модели. Кроме того, L2 регуляризация может помочь в предотвращении переобучения и улучшении обобщающей способности модели, а также в уменьшении влияния шума в данных на модель."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a818981",
   "metadata": {},
   "source": [
    "### Задание 2. По какому принципу рассчитывается \"важность признака (feature_importance)\" в ансамблях деревьев?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5125425e",
   "metadata": {},
   "source": [
    "Важность рассчитывается для отдельного дерева решений по величине, на которую каждая точка разделения \n",
    "атрибута улучшает показатель производительности, взвешенный по количеству наблюдений, за которые отвечает узел. \n",
    "Показателем производительности может быть чистота (индекс Джини), используемая для выбора точек разделения, \n",
    "или другая более конкретная функция ошибок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af28b78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16c23ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
